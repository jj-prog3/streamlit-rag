import streamlit as st
from pathlib import Path

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ChromaDB ìµœì¢…ë³¸)
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.vectorstores import Chroma # ChromaDB ì‚¬ìš©
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import AIMessage, HumanMessage

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ğŸ“„ Chat with Document",
    page_icon="ğŸ“„",
    layout="wide"
)
st.title("ğŸ“„ ë¬¸ì„œ ê¸°ë°˜ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜")

# --- ì‚¬ì´ë“œë°” ì„¤ì • ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    api_key = st.text_input(
        "OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”",
        type="password",
        help="API í‚¤ëŠ” OpenAI ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    uploaded_file = st.file_uploader(
        "ë¶„ì„í•  ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (.txt)",
        type=["txt"]
    )
    st.markdown("---")
    st.markdown(
        "â¤ï¸ [GitHub Repository](https://github.com/jj-prog3/streamlit-rag)"
    )

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "chain" not in st.session_state:
    st.session_state.chain = None
if "messages" not in st.session_state:
    st.session_state.messages = [
        AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ë¶„ì„í•  ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸ì„ ì‹œì‘í•˜ì„¸ìš”.")
    ]

# --- í•µì‹¬ ë¡œì§: íŒŒì¼ ì²˜ë¦¬ ë° ì²´ì¸ ìƒì„± ---
@st.cache_resource(show_spinner="â³ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
def process_file_and_create_chain(_api_key, _uploaded_file):
    try:
        file_content = _uploaded_file.getvalue().decode("utf-8")
        docs = [Document(page_content=file_content)]

        splitter = CharacterTextSplitter.from_tiktoken_encoder(
            chunk_size=500, chunk_overlap=50
        )
        split_docs = splitter.split_documents(docs)

        embeddings = OpenAIEmbeddings(openai_api_key=_api_key)
        
        # Chromaë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        vectorstore = Chroma.from_documents(split_docs, embeddings)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

        prompt = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\në¬¸ì„œ ë‚´ìš©ì— ì—†ëŠ” ì •ë³´ëŠ” ë‹µë³€í•˜ì§€ ë§ê³ , ëª¨ë¥¸ë‹¤ê³  ì†”ì§í•˜ê²Œ ë§í•˜ì„¸ìš”.\n\nContext:\n{context}"),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}"),
        ])

        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        rag_chain = (
            {
                "context": retriever | format_docs, 
                "question": RunnablePassthrough(),
                "history": lambda x: st.session_state.get('messages', [])
            }
            | prompt
            | ChatOpenAI(temperature=0.1, max_tokens=1024, openai_api_key=_api_key)
            | StrOutputParser()
        )
        return rag_chain
    
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# --- ë©”ì¸ í™”ë©´ ë¡œì§ ---
if api_key and uploaded_file:
    # íŒŒì¼ì´ ë³€ê²½ë˜ë©´ ì²´ì¸ì„ ë‹¤ì‹œ ìƒì„±
    st.session_state.chain = process_file_and_create_chain(api_key, uploaded_file)
    
    if "new_file" not in st.session_state or st.session_state.new_file != uploaded_file.name:
        st.session_state.new_file = uploaded_file.name
        st.session_state.messages = [
            AIMessage(content=f"'{uploaded_file.name}'ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
        ]
else:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API Keyë¥¼ ì…ë ¥í•˜ê³  ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.messages:
    role = "assistant" if isinstance(msg, AIMessage) else "user"
    st.chat_message(role).write(msg.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_query := st.chat_input("ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    if not st.session_state.chain:
        st.warning("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        st.session_state.messages.append(HumanMessage(content=user_query))
        st.chat_message("user").write(user_query)

        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = st.session_state.chain.invoke(user_query)
            st.session_state.messages.append(AIMessage(content=response))
            st.chat_message("assistant").write(response)